{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b82498a",
   "metadata": {},
   "source": [
    "# Object Detection using YOLO packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbce72",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2f0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae60d6a",
   "metadata": {},
   "source": [
    "### Predicting the still images given as sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5be463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Arighna\\OneDrive\\Desktop\\Machine Learning\\Face Detection\\Sample Images\\car.jpg: 416x640 1 person, 14 cars, 6 trucks, 752.7ms\n",
      "Speed: 2.0ms preprocess, 752.7ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Arighna\\OneDrive\\Desktop\\Machine Learning\\Face Detection\\Sample Images\\people1.jpg: 448x640 7 persons, 1 chair, 1 couch, 2 potted plants, 2 laptops, 1 cell phone, 940.1ms\n",
      "Speed: 5.1ms preprocess, 940.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Arighna\\OneDrive\\Desktop\\Machine Learning\\Face Detection\\Sample Images\\people2.jpg: 352x640 19 persons, 813.7ms\n",
      "Speed: 2.0ms preprocess, 813.7ms inference, 3.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Arighna\\OneDrive\\Desktop\\Machine Learning\\Face Detection\\Sample Images\\clock.jpg: 640x640 9 clocks, 1124.6ms\n",
      "Speed: 4.0ms preprocess, 1124.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\Arighna\\OneDrive\\Desktop\\Machine Learning\\Face Detection\\Sample Images\\people3.jpg: 320x640 9 persons, 627.7ms\n",
      "Speed: 2.1ms preprocess, 627.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "#Using the yolo Version 8 for better prediction\n",
    "\n",
    "model = YOLO('Yolo-Weights/yolov8l.pt')\n",
    "results1 = model(\"Sample Images/car.jpg\", show=True)\n",
    "results2 = model(\"Sample Images/people1.jpg\", show=True)\n",
    "results3 = model(\"Sample Images/people2.jpg\", show=True)\n",
    "results4 = model(\"Sample Images/clock.jpg\", show=True)\n",
    "results5= model(\"Sample Images/people3.jpg\", show=True)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00ae0e",
   "metadata": {},
   "source": [
    "### Object Detection using live video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c0f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)  # For Webcam\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "#cap = cv2.VideoCapture(\"../Videos/motorbikes.mp4\")  # For Video\n",
    "\n",
    "\n",
    "model = YOLO(\"Yolo-Weights/yolov8l.pt\")\n",
    "\n",
    "#Classnames of the bounding boxes\n",
    "\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while True:\n",
    "    new_frame_time = time.time()\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=1, thickness=1)\n",
    "\n",
    "    fps = 1 / (new_frame_time - prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    print(fps)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
